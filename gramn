#!/usr/bin/env python3
import requests
import sys
from pathlib import Path
import json
from html.parser import HTMLParser
import re
from dotenv import load_dotenv
load_dotenv()
import os
import colorama as cm
cm.init()
from colorama import Fore as _f, Back as _b, Style as _s

saplin = os.getenv('SAPLIN_KEY')
mocked_return = True
debug_raw_response = False
debug_raw_post = True

def absolute(file):
  return os.path.join(os.path.dirname(os.path.abspath(__file__)), file)

user_dict = ''
if Path(absolute('user_dict')).exists():
  user_dict = Path(absolute('user_dict')).read_text().splitlines()

class TextExtractor(HTMLParser):
  def __init__(self):
    super().__init__()
    self.text = ''
    self.ignore_alts = []
    if Path(absolute('ignore_alts')).exists():
      self.ignore_alts = Path(absolute('ignore_alts')).read_text().splitlines()
  def handle_data(self, data):
    new_data = ''
    for c in data:
      if c.isprintable() or c.isspace():
        new_data += c;
        next
    new_data = re.sub('\s+', ' ', new_data)
    self.text += new_data
    self.curate()
  def handle_starttag(self, tag, attrs):
    if tag == 'br':
      self.text += ' '
    if tag == 'img':
      for attr, value in attrs:
        if attr == 'alt' and value.strip():
          self.text += '' + value.strip() + ' '
          self.curate()
  def curate(self):
    if len(self.text) < 2:
      return
    self.text = re.sub('(\s|\|){2,}', ' | ', self.text)
    self.text = re.sub('^(\s|\|)+', '', self.text)
    for i in self.ignore_alts:
      reg = f'\| {i}'
      self.text = re.sub(reg, '', self.text)
    self.text = re.sub('\| ([a-zà-ü])', '\g<1>', self.text)

def extract_text_and_alt_tags(html_content):
  parser = TextExtractor()
  parser.feed(html_content)
  return parser.text

def api_call(data) -> dict:
  if mocked_return:
    return json.loads(Path(absolute('scraps/output.json')).read_text())['edits']
  try:
    response = requests.post(
      'https://api.sapling.ai/api/v1/edits',
      json = data
    )
    resp_json = response.json()
    if 200 <= response.status_code < 300:
      return resp_json['edits']
    else:
      print('Error: ', resp_json)
  except Exception as e:
    print('Error: ', e)

def prepare(content = ''):
  data = {
    'key': saplin,
    'text': content,
    'session_id': 'gramn'
  }
  return data

def report_errors(response):
  out = []
  for e in response:
    good = True
    s = e['sentence']
    error = s[e['start']:e['end']]
    for d in user_dict:
      if error == '+GV':
        print(d)
      if d == error:
        good = False
        break
    if not good:
      continue
    msg = ''
    msg += _s.DIM + _f.CYAN + e['error_type'] + ' '
    msg += ' ' * (8 - len(e['error_type']))
    msg += _f.WHITE + s[:e['start']]
    msg += _f.RED + error + _f.WHITE
    msg += s[e['end']:]
    r = e['replacement']
    if len(r):
      msg += ' ' + _f.GREEN + r + _f.WHITE
    msg += _s.RESET_ALL
    out.append(msg)
  return out

if __name__ == '__main__':
  if len(sys.argv) != 2:
    print('Missing file argument.')
    sys.exit(1)
  file = sys.argv[1]
  raw_content = Path(file).read_text()
  content = extract_text_and_alt_tags(raw_content)
  up = prepare(content)
  payload = str(up)
  dn = api_call(up)
  errors = report_errors(dn)
  # outputs:
  if debug_raw_post: print('> (' + str(len(payload)) + ') ' + payload)
  if debug_raw_response: print('< ' + dn)
  for e in errors:
    print(e)
